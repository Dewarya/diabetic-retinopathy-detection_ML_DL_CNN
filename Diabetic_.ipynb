{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1zZFGoMC4WwwdFHeXB2GtsINjZjQvIXDo",
      "authorship_tag": "ABX9TyPd+T+HEKcHojsOnsvIL40v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dewarya/diabetic-retinopathy-detection_ML_DL_CNN/blob/main/Diabetic_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ZKtbdqucvoEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "as09CA7kwZR_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cp /content/drive/MyDrive/kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "W0_itCMov4-D"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "d66zFWN6wexG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d sovitrath/diabetic-retinopathy-224x224-2019-data"
      ],
      "metadata": {
        "id": "4gi5Fp6jwmzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('/content/diabetic-retinopathy-224x224-2019-data.zip','r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "McWZ-VP8wn3-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from pathlib import Path\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from keras.preprocessing import image\n"
      ],
      "metadata": {
        "id": "BwnNra1HxqYM"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"/content/train.csv\")"
      ],
      "metadata": {
        "id": "HES3eBM2jvlu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "tbZCeaH_o0g-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add an additional column, mapping to the type\n",
        "df = pd.read_csv(r'/content/train.csv')\n",
        "\n",
        "diagnosis_dict_binary = {\n",
        "    0: 'No_DR',\n",
        "    1: 'DR',\n",
        "    2: 'DR',\n",
        "    3: 'DR',\n",
        "    4: 'DR'\n",
        "}\n",
        "\n",
        "diagnosis_dict = {\n",
        "    0: 'No_DR',\n",
        "    1: 'Mild',\n",
        "    2: 'Moderate',\n",
        "    3: 'Severe',\n",
        "    4: 'Proliferate_DR',\n",
        "}\n",
        "\n",
        "\n",
        "df['binary_type'] =  df['diagnosis'].map(diagnosis_dict_binary.get)\n",
        "df['type'] = df['diagnosis'].map(diagnosis_dict.get)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "4wVVwpHTyBoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into stratified train, val, and test sets\n",
        "train_intermediate, val = train_test_split(df, test_size=0.15, stratify=df['type'])\n",
        "train, test = train_test_split(train_intermediate, test_size=0.15 / (1 - 0.15), stratify=train_intermediate['type'])\n",
        "\n",
        "print(train['type'].value_counts(), '\\n')\n",
        "print(test['type'].value_counts(), '\\n')\n",
        "print(val['type'].value_counts(), '\\n')"
      ],
      "metadata": {
        "id": "NvD7CvE6pP6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create working directories for train/val/test\n",
        "base_dir = Path('/content/DL_Diabetic_Retinopathy')\n",
        "train_dir = base_dir / 'train'\n",
        "val_dir = base_dir / 'val'\n",
        "test_dir = base_dir / 'test'\n",
        "\n",
        "# Create directories\n",
        "for directory in [base_dir, train_dir, val_dir, test_dir]:\n",
        "    directory.mkdir(parents=True, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "FGRgEveJqg2o"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy images to respective working directory\n",
        "src_dir = Path('/content/colored_images')\n",
        "for index, row in train.iterrows():\n",
        "    diagnosis = row['type']\n",
        "    binary_diagnosis = row['binary_type']\n",
        "    id_code = row['id_code'] + \".png\"\n",
        "    srcfile = src_dir / diagnosis / id_code\n",
        "    dstfile = train_dir / binary_diagnosis / id_code\n",
        "    dstfile.parent.mkdir(parents=True, exist_ok=True)  # Ensure parent directory exists\n",
        "    with open(srcfile, 'rb') as src, open(dstfile, 'wb') as dst:\n",
        "        dst.write(src.read())\n",
        "\n",
        "for index, row in val.iterrows():\n",
        "    diagnosis = row['type']\n",
        "    binary_diagnosis = row['binary_type']\n",
        "    id_code = row['id_code'] + \".png\"\n",
        "    srcfile = src_dir / diagnosis / id_code\n",
        "    dstfile = val_dir / binary_diagnosis / id_code\n",
        "    dstfile.parent.mkdir(parents=True, exist_ok=True)  # Ensure parent directory exists\n",
        "    with open(srcfile, 'rb') as src, open(dstfile, 'wb') as dst:\n",
        "        dst.write(src.read())\n",
        "\n",
        "for index, row in test.iterrows():\n",
        "    diagnosis = row['type']\n",
        "    binary_diagnosis = row['binary_type']\n",
        "    id_code = row['id_code'] + \".png\"\n",
        "    srcfile = src_dir / diagnosis / id_code\n",
        "    dstfile = test_dir / binary_diagnosis / id_code\n",
        "    dstfile.parent.mkdir(parents=True, exist_ok=True)  # Ensure parent directory exists\n",
        "    with open(srcfile, 'rb') as src, open(dstfile, 'wb') as dst:\n",
        "        dst.write(src.read())"
      ],
      "metadata": {
        "id": "hk_2iAkxyZF8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_batches = ImageDataGenerator(rescale=1./255).flow_from_directory(train_dir, target_size=(224, 224), batch_size=32)\n",
        "val_batches = ImageDataGenerator(rescale=1./255).flow_from_directory(val_dir, target_size=(224, 224), batch_size=32)\n",
        "test_batches = ImageDataGenerator(rescale=1./255).flow_from_directory(test_dir, target_size=(224, 224), batch_size=32)\n"
      ],
      "metadata": {
        "id": "mTK7HsDTyjfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2QA7xhzTUQJp"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the model\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(8, (3,3), padding=\"valid\", input_shape=(224,224,3), activation = 'relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "\n",
        "    tf.keras.layers.Conv2D(16, (3,3), padding=\"valid\", activation = 'relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "\n",
        "    tf.keras.layers.Conv2D(32, (4,4), padding=\"valid\", activation = 'relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(32, activation = 'relu'),\n",
        "    tf.keras.layers.Dropout(0.15),\n",
        "    tf.keras.layers.Dense(2, activation = 'softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = 0.0001),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "rXeuS9Cfy1Lm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_batches,\n",
        "                    epochs=10,\n",
        "                    validation_data=val_batches)\n",
        "\n",
        "loss, acc = model.evaluate_generator(test_batches, verbose=1)\n",
        "print(\"Accuracy: \", acc)\n"
      ],
      "metadata": {
        "id": "REyB6rbBaeeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "d283womMd3LD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "predictions = model.predict(test_batches)\n",
        "y_true = test_batches.classes\n",
        "y_pred = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Compute confusion matrix\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9BnBE6iR-6DV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Class indices:\", train_batches.class_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mhc7x4lrFWVy",
        "outputId": "868f7101-41ef-496e-9fd9-b564e5c86299"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class indices: {'DR': 0, 'No_DR': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the image you want to test\n",
        "test_image_path = \"/content/25046-retinal-imaging.png\"\n",
        "test_image = image.load_img(test_image_path, target_size=(224, 224))\n",
        "test_image_array = image.img_to_array(test_image)\n",
        "test_image_array = np.expand_dims(test_image_array, axis=0)\n",
        "\n",
        "# Preprocess the image\n",
        "preprocessed_test_image = test_image_array / 255.0  # Normalize pixel values\n",
        "\n",
        "# Use the trained model to make predictions\n",
        "predictions = model.predict(preprocessed_test_image)\n",
        "predicted_class_index = np.argmax(predictions)\n",
        "\n",
        "# Reverse the class indices dictionary\n",
        "class_labels = {v: k for k, v in train_batches.class_indices.items()}\n",
        "\n",
        "# Get the predicted class label using the reversed dictionary\n",
        "predicted_class = class_labels[predicted_class_index]\n",
        "\n",
        "# Interpret the predictions\n",
        "print(\"Predicted class:\", predicted_class)\n",
        "print(\"Predicted probabilities:\", predictions)"
      ],
      "metadata": {
        "id": "pOGu2-mhAnTZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f7780c3-c366-416f-d9c3-a505afcb174d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 268ms/step\n",
            "Predicted class: No_DR\n",
            "Predicted probabilities: [[3.3655514e-09 1.0000000e+00]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the image you want to test\n",
        "test_image_path = \"/content/0083ee8054ee.png\"\n",
        "test_image = image.load_img(test_image_path, target_size=(224, 224))\n",
        "test_image_array = image.img_to_array(test_image)\n",
        "test_image_array = np.expand_dims(test_image_array, axis=0)\n",
        "\n",
        "# Preprocess the image\n",
        "preprocessed_test_image = test_image_array / 255.0  # Normalize pixel values\n",
        "\n",
        "# Use the trained model to make predictions\n",
        "predictions = model.predict(preprocessed_test_image)\n",
        "predicted_class_index = np.argmax(predictions)\n",
        "\n",
        "# Reverse the class indices dictionary\n",
        "class_labels = {v: k for k, v in train_batches.class_indices.items()}\n",
        "\n",
        "# Get the predicted class label using the reversed dictionary\n",
        "predicted_class = class_labels[predicted_class_index]\n",
        "\n",
        "# Interpret the predictions\n",
        "print(\"Predicted class:\", predicted_class)\n",
        "print(\"Predicted probabilities:\", predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rq-wjUIFFx5",
        "outputId": "83b27611-dc17-4fa6-9cec-f83d347358e3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 33ms/step\n",
            "Predicted class: DR\n",
            "Predicted probabilities: [[9.9999988e-01 8.9387775e-08]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wP9WwO_hwaiA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}